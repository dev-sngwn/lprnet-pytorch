{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import (\n",
    "    Adam,\n",
    "    lr_scheduler\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import (\n",
    "    Image,\n",
    "    ImageDraw,\n",
    "    ImageFont,\n",
    "    ImageFilter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallBasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, \n",
    "        out_channels,\n",
    "        activation,\n",
    "        config\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Small Basic Block\n",
    "        \n",
    "        :param in_channels: Channel of Input Tensor (int)\n",
    "        :param out_channels: Channel of Output Tensor (int)\n",
    "        :param activation: Activation Function (torch.nn)\n",
    "        :param config:\n",
    "            config[\"sbb_factor\"]: Divisor of SBB's Hidden Size (int)   default: 4\n",
    "            config[\"sbb_kernel_size\"]: SBB Convolution Kernel Size (Odd int)   default: 5\n",
    "        \"\"\"\n",
    "        super(SmallBasicBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.hidden_size = self.out_channels // config[\"sbb_factor\"]\n",
    "        self.kernel_size = config[\"sbb_kernel_size\"]\n",
    "        self.activation = activation\n",
    "            \n",
    "        self.bn = nn.BatchNorm2d(self.hidden_size)\n",
    "            \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.hidden_size,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            #self.bn,\n",
    "            self.activation,\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_size,\n",
    "                out_channels=self.hidden_size,\n",
    "                kernel_size=(self.kernel_size, 1),\n",
    "                padding=(self.kernel_size // 2, 0)\n",
    "            ), \n",
    "            #self.bn,\n",
    "            self.activation,\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_size,\n",
    "                out_channels=self.hidden_size,\n",
    "                kernel_size=(1, self.kernel_size),\n",
    "                padding=(0, self.kernel_size // 2),\n",
    "            ), \n",
    "            #self.bn,\n",
    "            self.activation,\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_size,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        activation\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Convolution Include Activation & Batch Normalization\n",
    "        \n",
    "        :param in_channels: Channel of Input Tensor (int)\n",
    "        :param out_channels: Channel of Output Tensor (int)\n",
    "        :param kernel_size: Kernel Size of Convolution Layer (int / tuple)\n",
    "        :param stride: Stride of Convolution Layer (int / tuple)\n",
    "        :param padding: Padding Size of Convolution Layer (int / tuple)\n",
    "        :param activation: Activation Function (torch.nn)\n",
    "        \"\"\"\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        \n",
    "        if self.activation != None:\n",
    "            return self.activation(x)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    \n",
    "class LPRNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        LPRNet (https://arxiv.org/abs/1806.10447)\n",
    "        \n",
    "        :param config:\n",
    "            config[\"class_num\"]: Num of Class (int)\n",
    "            config[\"in_channels\"]: Input's Channel Size (int)   default: 3\n",
    "            config[\"hidden_size\"]: Hidden Size of Convolution Layer (int)   default: 64\n",
    "            config[\"kernel_hidden\"]: Convolution Layer's Kernel Width (int)   default: 3\n",
    "            config[\"kernel_wide\"]: Inter Dropout Convolution Layer's Kernel Width (int)   default: 4\n",
    "            config[\"kernel_out\"]: Final Convolution Layer's Kernel Width (int)   default: 13\n",
    "            cofing[\"activation\"]: \"relu\" / \"relu6\" / \"leaky_relu\" / \"prelu\" (str)   default: \"relu\"\n",
    "            cofing[\"dropout\"]: Dropout Rate (float)   default: 0.5\n",
    "        \"\"\"\n",
    "        super(LPRNet, self).__init__()\n",
    "    \n",
    "        self.class_num     = config[\"class_num\"]\n",
    "        self.in_channels   = config[\"in_channels\"]\n",
    "        self.hidden_size   = config[\"hidden_size\"]\n",
    "        self.kernel_hidden = config[\"kernel_hidden\"]\n",
    "        self.kernel_wide   = config[\"kernel_wide\"]\n",
    "        self.kernel_out    = config[\"kernel_out\"]\n",
    "        self.act_conf      = config[\"activation\"].lower()\n",
    "        self.dropout       = config[\"dropout\"]\n",
    "        \n",
    "        if self.act_conf == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif self.act_conf == \"relu6\":\n",
    "            self.activation = nn.ReLU6()\n",
    "        elif self.act_conf == \"leaky_relu\":\n",
    "            self.activation = nn.LeakyReLU(0.2)\n",
    "        elif self.act_conf == \"prelu\":\n",
    "            self.activation = nn.PReLU()\n",
    "            \n",
    "        self.backbone = nn.Sequential(\n",
    "            ConvBlock(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.hidden_size,\n",
    "                kernel_size=self.kernel_hidden,\n",
    "                stride=1,\n",
    "                padding=self.kernel_hidden//2,\n",
    "                activation=self.activation\n",
    "            ),\n",
    "            nn.MaxPool3d(\n",
    "                kernel_size=(1, 3, 3),\n",
    "                stride=(1, 1, 1)\n",
    "            ),\n",
    "            \n",
    "            SmallBasicBlock(\n",
    "                in_channels=self.hidden_size, \n",
    "                out_channels=self.hidden_size*2,\n",
    "                activation=self.activation,\n",
    "                config=config\n",
    "            ),\n",
    "            nn.MaxPool3d(\n",
    "                kernel_size=(1, 3, 3),\n",
    "                stride=(2, 1, 2)\n",
    "            ),\n",
    "            \n",
    "            SmallBasicBlock(\n",
    "                in_channels=self.hidden_size, \n",
    "                out_channels=self.hidden_size*4,\n",
    "                activation=self.activation,\n",
    "                config=config\n",
    "            ),\n",
    "            SmallBasicBlock(\n",
    "                in_channels=self.hidden_size*4, \n",
    "                out_channels=self.hidden_size*4,\n",
    "                activation=self.activation,\n",
    "                config=config\n",
    "            ),\n",
    "            nn.MaxPool3d(\n",
    "                kernel_size=(1, 3, 3),\n",
    "                stride=(4, 1, 2)\n",
    "            ),\n",
    "            \n",
    "            nn.Dropout(self.dropout),\n",
    "            ConvBlock(\n",
    "                in_channels=self.hidden_size,\n",
    "                out_channels=self.hidden_size*4,\n",
    "                kernel_size=(1, self.kernel_wide),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                activation=self.activation\n",
    "            ),\n",
    "            nn.Dropout(self.dropout),\n",
    "            ConvBlock(\n",
    "                in_channels=self.hidden_size*4,\n",
    "                out_channels=self.class_num,\n",
    "                kernel_size=(self.kernel_out, 1),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                activation=None\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.backbone.apply(self.init_weights)\n",
    "        \n",
    "        \n",
    "    def init_weights(self, layer):\n",
    "        init_layer_list = [nn.Linear, nn.Conv2d]\n",
    "        \n",
    "        if type(layer) in init_layer_list:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoreanLPDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_list,\n",
    "        class_dict,\n",
    "        data_size\n",
    "    ):\n",
    "        self.x = image_list\n",
    "        self.class_dict = class_dict\n",
    "        self.data_size = data_size\n",
    "        \n",
    "        self.labels = self.build_sequences(image_list)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def norm_img(self, img):        \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "        dilated = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)\n",
    "        \n",
    "        median = cv2.medianBlur(dilated, 15)\n",
    "        diff = 255 - cv2.subtract(median, img)\n",
    "\n",
    "        normed = cv2.normalize(diff, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        normed = cv2.resize(normed, self.data_size)\n",
    "\n",
    "        return normed\n",
    "    \n",
    "    \n",
    "    def img_to_tensor(self, img, factor=255.):\n",
    "        arr = (self.norm_img(np.array(img))) / factor\n",
    "        \n",
    "        return torch.tensor(arr, dtype=torch.float32).transpose(0, 2).transpose(1, 2)\n",
    "    \n",
    "\n",
    "    def build_sequences(self, image_list):\n",
    "        labels = list()\n",
    "\n",
    "        for img in image_list:\n",
    "            class_seq = os.path.basename(img)[:-4]\n",
    "\n",
    "            sequence = list()\n",
    "            for char in class_seq:\n",
    "                sequence.append(self.class_dict[char])\n",
    "\n",
    "            labels.append(sequence)\n",
    "\n",
    "        return np.array(labels)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.x[idx])\n",
    "        label = self.labels[idx]\n",
    "        tgt_len = len(label)\n",
    "        \n",
    "        return self.img_to_tensor(img), label, tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBERS = [\n",
    "    \"<BLANK>\",\n",
    "    '0', '1', '2', '3', '4',\n",
    "    '5', '6', '7', '8', '9'\n",
    "]\n",
    "\n",
    "CHARS = [\n",
    "    # 자가용\n",
    "    '가', '나', '다', '라', '마',\n",
    "    '거', '너', '더', '러', '머', '버', '서', '어', '저', \n",
    "    '고', '노', '도', '로', '모', '보', '소', '오', '조',\n",
    "    '구', '누', '두', '루', '무', '부', '수', '우', '주',\n",
    "    \n",
    "    # 사업용\n",
    "    '바', '사', '아', '자',\n",
    "    \n",
    "    # 군용\n",
    "    '공', '해', '육', '합',\n",
    "    \n",
    "    # 기타\n",
    "    '허', '하', '호', '배'\n",
    "]\n",
    "\n",
    "CLASS_DICT = {num:i for i, num in enumerate(NUMBERS + CHARS)}\n",
    "idx_to_word = {y:x for x,y in CLASS_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = glob.glob(\"./dataset/train/*\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ds_train = KoreanLPDataset(\n",
    "    image_list=train_imgs,\n",
    "    class_dict=CLASS_DICT,\n",
    "    data_size=(94, 24)\n",
    ")\n",
    "train_loader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = glob.glob(\"../dataset/test/*.jpg\")\n",
    "\n",
    "ds_test = KoreanLPDataset(\n",
    "    image_list=data_list,\n",
    "    class_dict=CLASS_DICT,\n",
    "    data_size=(94, 24)\n",
    ")\n",
    "test_loader = DataLoader(ds_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model_config = {\n",
    "    \"class_num\": len(CLASS_DICT),\n",
    "    \"in_channels\": 3,\n",
    "    \"hidden_size\": 64,\n",
    "    \"kernel_hidden\": 3,\n",
    "    \"kernel_wide\": 4,\n",
    "    \"kernel_out\": 13,\n",
    "    \"sbb_factor\": 4,\n",
    "    \"sbb_kernel_size\": 5,\n",
    "    \"activation\": \"relu\",\n",
    "    \"dropout\": 0.5\n",
    "}\n",
    "\n",
    "model = LPRNet(model_config)\n",
    "\n",
    "K = 1000\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer=optimizer,\n",
    "    step_size=100*K,\n",
    "    gamma=0.1\n",
    ")\n",
    "loss_fn = nn.CTCLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "print(\"Trainable Parameters:\", count_parameters(model))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decoding(logits_batch, idx_to_word):\n",
    "    logits_batch = logits_batch.transpose(1, 2)\n",
    "\n",
    "    results = list()\n",
    "    for logits in logits_batch:\n",
    "        result = list()\n",
    "        tmp = 0\n",
    "\n",
    "        for _class in torch.argmax(logits, dim=-1).cpu().detach().numpy():\n",
    "\n",
    "            if tmp == _class: continue\n",
    "\n",
    "            if _class == 0: \n",
    "                tmp = 0\n",
    "                continue # Blank\n",
    "\n",
    "            else:\n",
    "                result.append(idx_to_word[_class])\n",
    "                tmp = _class\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "\n",
    "def evaluation(model, _iter, idx_to_word):\n",
    "    global best_score\n",
    "    accu = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(_iter):\n",
    "        lps, labels, tgt_len = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            lps = lps.cuda()\n",
    "            labels = labels.cuda()\n",
    "            tgt_len = tgt_len.cuda()\n",
    "\n",
    "            logits = model(lps)\n",
    "\n",
    "            gold = [idx_to_word[c] for c in labels[0].cpu().detach().numpy()]\n",
    "            pred = ctc_decoding(logits, idx_to_word)[0]\n",
    "            \n",
    "            score = 0\n",
    "            for idx in range(7):\n",
    "                if idx >= len(pred): continue\n",
    "                if gold[idx] == str(pred[idx]): score += 1\n",
    "\n",
    "            accu += score / 7\n",
    "            print(\"\\rAccuracy %.4lf\" % ((accu / (batch_idx + 1))), end=\"\")\n",
    "                \n",
    "    if best_score < (accu / (batch_idx + 1)):\n",
    "        best_score = (accu / (batch_idx + 1))\n",
    "        print(\"\\nBest Score! %.4lf\" % best_score)\n",
    "        torch.save(model.state_dict(), \"./lprnet.pth\")\n",
    "                     \n",
    "    print(\"\\nGold:\", gold)\n",
    "    print(\"Pred:\", pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "iteration = 0\n",
    "history = list()\n",
    "\n",
    "print(\">> Training Start:\", datetime.datetime.now())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    start_time = datetime.datetime.now()\n",
    "    batch_loss = 0.0\n",
    "    print(\">> Current Learning Rate:\", scheduler.get_last_lr())\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        lps, labels, tgt_len = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            lps = lps.cuda()\n",
    "            labels = labels.cuda()\n",
    "            tgt_len = tgt_len.cuda()\n",
    "\n",
    "        logits = model(lps)\n",
    "        logits = logits.transpose(0, 2).transpose(1, 2)\n",
    "        \n",
    "        src_len = torch.full(\n",
    "            size=(lps.shape[0],),\n",
    "            fill_value=logits.shape[0],\n",
    "            dtype=torch.long\n",
    "        ).cuda()\n",
    "\n",
    "        loss = loss_fn(logits, labels, src_len, tgt_len)\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        print(\"\\r>> Epoch: %4d | Iteration: %6d | Process: %4d / %4d | Loss: %.4lf\" % \\\n",
    "              (epoch+1, iteration, batch_idx+1, train_loader.__len__(), (batch_loss / (batch_idx + 1))), end=\"\")\n",
    "    \n",
    "    history.append((epoch+1, (batch_loss / (batch_idx + 1))))\n",
    "    \n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"\\n>> Time / Epoch: \", end_time - start_time)\n",
    "    \n",
    "    model.eval()\n",
    "    evaluation(model, test_loader)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
